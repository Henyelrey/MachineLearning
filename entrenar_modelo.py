import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error
import pandas as pd
import joblib
import matplotlib.pyplot as plt

# ==============================================================================
# 1Ô∏è‚É£ Cargar el dataset limpio
# ==============================================================================
df = pd.read_csv("casas_limpias.csv")

# Comprobamos que exista la columna 'price'
if 'price' not in df.columns:
    print("‚ùå No se encontr√≥ la columna 'price'. Ren√≥mbrala en tu CSV.")
    exit()

# ==============================================================================
# 2Ô∏è‚É£ Separar variables num√©ricas y categ√≥ricas
# ==============================================================================
# Separamos las variables num√©ricas y categ√≥ricas autom√°ticamente
numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
categorical_cols = df.select_dtypes(include=['object']).columns.tolist()

print(f"üìä Columnas num√©ricas: {numeric_cols}")
print(f"üî§ Columnas categ√≥ricas: {categorical_cols}")

# ==============================================================================
# 3Ô∏è‚É£ Convertir variables categ√≥ricas a num√©ricas (One-Hot Encoding)
# ==============================================================================
df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)

# ==============================================================================
# 4Ô∏è‚É£ Separar variables independientes (X) y dependiente (y)
# ==============================================================================
X = df_encoded.drop(columns=['price'])
y = df_encoded['price']

# ==============================================================================
# 5Ô∏è‚É£ Escalar caracter√≠sticas num√©ricas
# ==============================================================================
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# ==============================================================================
# 6Ô∏è‚É£ Dividir en entrenamiento y prueba
# ==============================================================================
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# ==============================================================================
# 7Ô∏è‚É£ Crear el modelo neuronal
# ==============================================================================
model = Sequential([
    Dense(64, input_dim=X.shape[1], activation='relu'),
    Dense(32, activation='relu'),
    Dense(16, activation='relu'),
    Dense(1, activation='linear')
])

model.compile(optimizer='adam', loss='mse')

# ==============================================================================
# 8Ô∏è‚É£ Entrenar el modelo
# ==============================================================================
history = model.fit(X_train, y_train, epochs=100, validation_split=0.2, verbose=1)

# ==============================================================================
# 9Ô∏è‚É£ Evaluar el modelo
# ==============================================================================
y_pred = model.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
print(f"\n‚úÖ MAE (Error Absoluto Medio): {mae:.2f}")

# ==============================================================================
# üîü Guardar modelo y escalador
# ==============================================================================
model.save("modelo_casas.keras")
joblib.dump(scaler, "scaler_casas.pkl")
print("\nüíæ Modelo y escalador guardados correctamente.")

# ==============================================================================
# 11Ô∏è‚É£ Graficar la p√©rdida del entrenamiento
# ==============================================================================
plt.figure(figsize=(8, 5))
plt.plot(history.history['loss'], label='Entrenamiento', linewidth=2)
plt.plot(history.history['val_loss'], label='Validaci√≥n', linewidth=2)
plt.legend()
plt.title("Evoluci√≥n del Error durante el Entrenamiento")
plt.xlabel("√âpocas")
plt.ylabel("Error cuadr√°tico medio (MSE)")
plt.show()

